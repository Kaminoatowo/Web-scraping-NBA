{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226cfd08",
   "metadata": {},
   "source": [
    "Predict who is going to be MVP in NBA: web scraping NBA data\n",
    "\n",
    "We need data on players, like scores during the championship\n",
    "\n",
    "Take data from https://www.basketball-reference.com/\n",
    "\n",
    "Take a look at https://www.basketball-reference.com/awards/awards_2020.html and inspect it before loading data: find the objects needed for the scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119924f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1991,2022)) #list of years we want to get data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a91a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b812704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b30158",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mvp/1991.html\", encoding=\"utf8\") as f:\n",
    "    page = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110963c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By inspecting the table we can see that the first row is not necessary, let's remove it\n",
    "# the row we want is identified by <tr class=\"over_header\">\n",
    "soup.find('tr', class_=\"over_header\").decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want a table from each page, let's remove all other staff\n",
    "mvp_table = soup.find_all(id=\"mvp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e061ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the first element to get a database\n",
    "mvp_1991 = pd.read_html(str(mvp_table))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a4a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mvp_1991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"mvp/{}.html\".format(year), encoding=\"utf8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_=\"over_header\").decompose()\n",
    "    mvp_table = soup.find(id=\"mvp\")\n",
    "    mvp = pd.read_html(str(mvp_table))[0]\n",
    "    mvp[\"Year\"] = year\n",
    "    \n",
    "    dfs.append(mvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b34fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9182cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fd379",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps.to_csv(\"mvps.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a9403",
   "metadata": {},
   "source": [
    "Now we have data from all players who actually WON the MVP\n",
    "\n",
    "We need to know the stats of all the players to see what the MVPs stand out for\n",
    "\n",
    "Stats per game for all players of NBA can be found in https://www.basketball-reference.com/leagues/NBA_2021_per_game.html for 2021 (as an example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90385778",
   "metadata": {},
   "source": [
    "Since the web page we're taking data from is responsive to a web browser to show all of data, what we typed above isn't going to give us the whole web page in the `1991.html` file\n",
    "\n",
    "We need to load the web page as a browser. To do so we will use selenium, and we need to know the chrome release we're using.\n",
    "\n",
    "E.g. I am using chrome 113 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee88bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea533bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"/Users/sirja/Codes/chromedriver_win32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1991\n",
    "with open(\"player/{}.html\".format(year), encoding=\"utf8\") as f:\n",
    "    page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    player_table = soup.find(id=\"per_game_stats\")\n",
    "    player = pd.read_html(str(player_table))[0]\n",
    "    player[\"Year\"] = year\n",
    "    \n",
    "    dfs.append(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "player.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ea0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "with open(\"player/{}.html\".format(year), encoding=\"utf8\") as f:\n",
    "    page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    player_table = soup.find(id=\"per_game_stats\")\n",
    "    player = pd.read_html(str(player_table))[0]\n",
    "    player[\"Year\"] = year\n",
    "    \n",
    "    dfs.append(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "player.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "del player\n",
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"player/{}.html\".format(year), encoding=\"utf8\") as f:\n",
    "        page = f.read()\n",
    "    \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        soup.find('tr', class_=\"thead\").decompose()\n",
    "        player_table = soup.find(id=\"per_game_stats\")\n",
    "        player = pd.read_html(str(player_table))[0]\n",
    "        player[\"Year\"] = year\n",
    "\n",
    "        dfs.append(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0481d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv(\"players.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a70f65",
   "metadata": {},
   "source": [
    "Team record matters a lot for the MVP race\n",
    "\n",
    "We need this data to correctly predict the MVP\n",
    "\n",
    "Take data from https://www.basketball-reference.com/leagues/NBA_2021_standings.html, in the specific, we are going to use data in the Division standings tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03967862",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1991\n",
    "with open(\"team/{}.html\".format(year), encoding=\"utf8\") as f:\n",
    "    page = f.read()\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "for div in soup.find_all(\"tr\", {'class':'thead'}): \n",
    "    div.decompose()\n",
    "#soup.find('tr', class_=\"thead\").decompose()\n",
    "team_table = soup.find(id=\"divs_standings_E\")\n",
    "team = pd.read_html(str(team_table))[0]\n",
    "team[\"Year\"] = year\n",
    "team[\"Team\"] = team[\"Eastern Conference\"]\n",
    "del team[\"Eastern Conference\"]\n",
    "#dfs.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374e4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del team\n",
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"team/{}.html\".format(year), encoding=\"utf8\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    for div in soup.find_all(\"tr\", {'class':'thead'}): \n",
    "        div.decompose()\n",
    "    team_table = soup.find(id=\"divs_standings_E\")\n",
    "    team = pd.read_html(str(team_table))[0]\n",
    "    team[\"Year\"] = year\n",
    "    team[\"Team\"] = team[\"Eastern Conference\"]\n",
    "    del team[\"Eastern Conference\"]\n",
    "    dfs.append(team)\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    for div in soup.find_all(\"tr\", {'class':'thead'}): \n",
    "        div.decompose()\n",
    "    team_table = soup.find(id=\"divs_standings_W\")\n",
    "    team = pd.read_html(str(team_table))[0]\n",
    "    team[\"Year\"] = year\n",
    "    team[\"Team\"] = team[\"Western Conference\"]\n",
    "    del team[\"Western Conference\"]\n",
    "    dfs.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c710563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c808ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.to_csv(\"teams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e008c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
